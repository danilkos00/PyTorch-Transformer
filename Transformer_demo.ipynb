{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 12080005,
          "sourceType": "datasetVersion",
          "datasetId": 7604456
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danilkos00/PyTorch-Transformer.git -qq\n",
        "\n",
        "%cd PyTorch-Transformer\n",
        "\n",
        "!pip install jaxtyping -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eixpNcTdDaxk",
        "outputId": "8365808d-4b14-46c8-a052-ebcf30848b82",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T09:57:56.463550Z",
          "iopub.execute_input": "2025-06-26T09:57:56.463744Z",
          "iopub.status.idle": "2025-06-26T09:57:57.256372Z",
          "shell.execute_reply.started": "2025-06-26T09:57:56.463721Z",
          "shell.execute_reply": "2025-06-26T09:57:57.255671Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyTorch-Transformer\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "\n",
        "params_url = 'https://drive.google.com/uc?id=1-L881Atoagz_0AXnwcKI28ZcWjq6NUy8'\n",
        "output_path = './ts_checkpoint.tar'\n",
        "gdown.download(params_url, output_path, quiet=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T10:11:11.848960Z",
          "iopub.execute_input": "2025-06-26T10:11:11.849843Z",
          "iopub.status.idle": "2025-06-26T10:11:16.612078Z",
          "shell.execute_reply.started": "2025-06-26T10:11:11.849813Z",
          "shell.execute_reply": "2025-06-26T10:11:16.611466Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cCJGNJtLxNKe",
        "outputId": "e7bec6f0-8bb2-45d8-c07c-8f7a662d6930"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./ts_checkpoint.tar'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "from data.dataset import load_dataset\n",
        "\n",
        "train_path, val_path = load_dataset(dataset_name='tinyStories')"
      ],
      "metadata": {
        "id": "E7h_EQ39LTsX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-25T21:34:17.767508Z",
          "iopub.execute_input": "2025-06-25T21:34:17.767708Z",
          "iopub.status.idle": "2025-06-25T21:34:18.126310Z",
          "shell.execute_reply.started": "2025-06-25T21:34:17.767691Z",
          "shell.execute_reply": "2025-06-25T21:34:18.125691Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from src.training import train\n",
        "\n",
        "train(train_path, val_path, config_path='./config/config.json', checkpoint='ts_checkpoint.tar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbB403AbL0tp",
        "outputId": "806bbe36-dc32-46cf-f35b-8064f851e110",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-25T21:35:04.730628Z",
          "iopub.execute_input": "2025-06-25T21:35:04.731203Z",
          "iopub.status.idle": "2025-06-26T09:14:57.320807Z",
          "shell.execute_reply.started": "2025-06-25T21:35:04.731175Z",
          "shell.execute_reply": "2025-06-26T09:14:57.320180Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 33000/33000 [11:39:50<00:00,  1.27s/it, lr=3.4275e-06, train_loss=1.4231, val_loss=1.3769, val_accuracy=0.64]  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from src.model import TransformerLM\n",
        "from src.tokenizer import Tokenizer\n",
        "from src.training import load_checkpoint\n",
        "\n",
        "\n",
        "with open('config/config.json', 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "model = TransformerLM(**config['model']).to('cuda')\n",
        "\n",
        "load_checkpoint('ts_checkpoint.tar', model)\n",
        "tokenizer = Tokenizer('tinyStories')"
      ],
      "metadata": {
        "id": "-xo6-L4SMZvX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T10:11:23.862210Z",
          "iopub.execute_input": "2025-06-26T10:11:23.862787Z",
          "iopub.status.idle": "2025-06-26T10:11:28.477022Z",
          "shell.execute_reply.started": "2025-06-26T10:11:23.862766Z",
          "shell.execute_reply": "2025-06-26T10:11:28.476457Z"
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate(\"Once upon a time\", tokenizer, 256, p=0.9, temperature=0.9)\n",
        "print('-'*50)\n",
        "model.generate(\"One day\", tokenizer, 256, p=0.9, temperature=0.9)\n",
        "print('-'*50)\n",
        "model.generate(\"Once upon a time\", tokenizer, 256, p=0.9, temperature=0.9)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T10:11:29.087143Z",
          "iopub.execute_input": "2025-06-26T10:11:29.087380Z",
          "iopub.status.idle": "2025-06-26T10:11:31.832666Z",
          "shell.execute_reply.started": "2025-06-26T10:11:29.087364Z",
          "shell.execute_reply": "2025-06-26T10:11:31.832135Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHE0TukwxNKf",
        "outputId": "41cd671a-b90c-41b8-a3e3-21ac0097c4e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, there was a big, proud cow named Bessie. Bessie lived on a farm with many other animals. She had a lot of friends, like the big, strong cow, and the little duck.\n",
            "One day, Bessie saw her friend, the little duck, feeling sad. Bessie asked, \"Why are you sad, little duck?\" The little duck said, \"I have no toys, and I am all alone.\" Bessie felt bad for the little duck and wanted to help.\n",
            "Bessie thought and thought. Then, she had an idea. She asked her friends, the cow, the pig, and the pig, to come and play with her. They all worked together, and soon the little duck was happy. Bessie was happy, and her friends were happy too. They all played together and had fun, and the little duck was glad to have a friend like Bessie.\n",
            "--------------------------------------------------\n",
            "One day, a smart cat named Tom was very tired. He wanted to take a nap under a big tree. Tom found a nice spot under the tree and lay down. The sun was warm and the wind was harsh. Tom felt so good.\n",
            "While Tom was napping, a small bird flew down and sat next to him. The bird said, \"Hi, Tom! What are you doing?\" Tom opened one eye and said, \"I am resting. I want a nap.\" The bird thought for a moment and said, \"I can help you get a good nap.\"\n",
            "The bird flew away and came back with a soft pillow. The bird put the pillow on the pillow. Tom lay down on the pillow and closed his eyes. The bird slept very well, and Tom felt so happy. When Tom woke up, he felt refreshed and ready to go to his nap.\n",
            "--------------------------------------------------\n",
            "Once upon a time, there was a big, impressive tree. It had many colorful leaves. One day, a little bird came to the tree. The bird was sad. It wanted to go to the other side of the forest.\n",
            "The bird asked the tree, \"Can you help me? I want to go to the other side of the forest, but I am too small.\" The tree said, \"I can help you, little bird.\" The bird told the tree to stay and wait. The tree did not listen to the bird.\n",
            "The next day, the bird saw a big hole in the tree. The bird tried to fly through the hole, but it was too big. The tree fell down and hurt its leaves. The bird could not fly away. The tree was very sad.\n",
            "The moral of the story is to listen to others and not to trust everything you do.\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Ibq0udwpxNKg"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}